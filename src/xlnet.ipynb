{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d817e21",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_725/635357764.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mUniversalBase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# GPU only packages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_helpers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseMetaClass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_tags_class_and_instance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from cuml.internals.api_decorators import (\n\u001b[1;32m     19\u001b[0m     \u001b[0m_deprecate_pos_args\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/base_helpers.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m from cuml.internals.api_decorators import (\n\u001b[0m\u001b[1;32m     21\u001b[0m     \u001b[0mapi_base_return_generic\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mapi_base_return_array\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/api_decorators.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# TODO: Try to resolve circular import that makes this necessary:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0minput_utils\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0miu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_context_managers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseReturnAnyCM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi_context_managers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseReturnArrayCM\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/input_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcollections\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnamedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCumlArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray_sparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSparseCumlArray\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_settings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalSettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/array.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_settings\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGlobalSettings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdebug\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_type\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemoryType\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMemoryTypeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/global_settings.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mthreading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavailable_devices\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_cuda_available\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_type\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeviceType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_type\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemoryType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/device_type.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0menum\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEnum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmem_type\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMemoryType\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/mem_type.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcuml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternals\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msafe_imports\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcpu_only_import\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpu_only_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mcudf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_only_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cudf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mcp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_only_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cupy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mcpx_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgpu_only_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cupyx.scipy.sparse\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cuml/internals/safe_imports.py\u001b[0m in \u001b[0;36mgpu_only_import\u001b[0;34m(module, alt)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \"\"\"\n\u001b[1;32m    355\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mGPU_ENABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         return safe_import(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/cudf/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mvalidate_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcupy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumba\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnumba_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import optim, nn, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import lightning.pytorch as pl\n",
    "\n",
    "from sklearn import model_selection\n",
    "from cuml.svm import SVC\n",
    "import cuml\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from transformers import XLNetTokenizer, XLNetModel, AutoTokenizer, AlbertModel, AutoModel, DebertaV2Model, DebertaV2Tokenizer, ElectraModel, RobertaModel, AlbertTokenizer\n",
    "\n",
    "from helper import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337043bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftMaxLit(pl.LightningModule):\n",
    "    \"\"\"\n",
    "    Reference\n",
    "    https://machinelearningmastery.com/introduction-to-softmax-classifier-in-pytorch/\n",
    "    \"\"\"\n",
    "    def __init__(self, n_inputs, n_outputs):\n",
    "        super().__init__()\n",
    "        self.linear = torch.nn.Linear(n_inputs, n_outputs)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.softmax(self.linear(x))\n",
    "        \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # training_step defines the train loop.\n",
    "        # it is independent of forward\n",
    "        x, y = batch\n",
    "        \n",
    "        y_hat = self(x)\n",
    "\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        \n",
    "        self.log('train_loss', loss)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr = 0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.01, amsgrad=False)\n",
    "        return optimizer\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        self.log(\"val_loss\", loss)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y = torch.argmax(y, dim=1)\n",
    "        y_hat = torch.argmax(self(x), dim=1)\n",
    "        accuracy = torch.sum(y == y_hat).item() / (len(y) * 1.0)\n",
    "        self.log('test_acc', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14dbd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data(Dataset):\n",
    "    \"The data for multi-class classification\"\n",
    "    def __init__(self, df, *, x=None, load_batch_size=None, tokenizer=None, cls_model=None):\n",
    "        self.y, self.len = self._get_y_and_len_from_df(df)\n",
    "        \n",
    "        if x is not None:\n",
    "            self.x = x\n",
    "        else:\n",
    "            self.x = self._get_x_from_df(df, load_batch_size, tokenizer, cls_model)\n",
    "        \n",
    "    def _get_x_from_df(self, df, load_batch_size, tokenizer, cls_model):\n",
    "        docs = df['text'].tolist()\n",
    "        inputs = tokenizer(docs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "        cls_arr = []\n",
    "        for i, (x, y) in zip(tqdm(range(math.ceil(len(df) / load_batch_size))), self._get_x_y_from_df_with_batch(df, load_batch_size)):\n",
    "            cls = cls_model(**{k: inputs[k][x:y] for k in list(inputs.keys())}).last_hidden_state[:, 0, :].detach()\n",
    "#             cls = cls_model(**{'input_ids':inputs['input_ids'][x:y],'token_type_ids':inputs['token_type_ids'][x:y],'attention_mask':inputs['attention_mask'][x:y]}).last_hidden_state[:, 0, :].detach()\n",
    "            cls_arr.append(cls)\n",
    "        return torch.concat(cls_arr)\n",
    "    \n",
    "    def _get_y_and_len_from_df(self, df):\n",
    "        dim_0 = df['text'].shape[0]\n",
    "        matrix = np.zeros((dim_0,2))\n",
    "        for i, y in enumerate(df['label'].tolist()):\n",
    "            matrix[i][y] = 1\n",
    "        return torch.from_numpy(matrix), dim_0\n",
    "\n",
    "    def _get_x_y_from_df_with_batch(self, df, step_size):\n",
    "        l = list(range(0, len(df), step_size))\n",
    "        for ind, _ in enumerate(l):\n",
    "            if l[ind] + step_size >= len(df):\n",
    "                yield (l[ind], len(df))\n",
    "            else:    \n",
    "                yield (l[ind], l[ind + 1])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"accessing one element in the dataset by index\"\n",
    "        return self.x[idx], self.y[idx] \n",
    " \n",
    "    def __len__(self):\n",
    "        \"size of the entire dataset\"\n",
    "        return self.len\n",
    "\n",
    "    @staticmethod\n",
    "    def concat(datasets):\n",
    "        \"concatenate dataset embeddings from x provided they are applied on the same df\"\n",
    "        x = torch.cat([dataset.x for dataset in datasets], 1)\n",
    "        return Data(df, x=x)\n",
    "\n",
    "# THIS IS LEGACY\n",
    "class DataLit(pl.LightningDataModule):\n",
    "    def __init__(self, batch_size = 4):\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def setup(self, stage):\n",
    "        df = load_dataset('../dataset/training.json', test=True)\n",
    "        dataset = Data(df[:100], 30)  # 10 > 30 > 40 yes # 4 is the best\n",
    "        self.train_dataset, self.val_dataset, self.test_dataset = utils.data.random_split(dataset,(0.8, 0.1, 0.1))\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(dataset = self.train_dataset, batch_size = self.batch_size, shuffle=True)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(dataset = self.val_dataset, batch_size = self.batch_size, shuffle=True)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(dataset = self.test_dataset, batch_size = self.batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282c3140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dataloaders(df=None, tokenizer=None, cls_model=None, batch_size=None, dataset=None):\n",
    "    if not dataset:\n",
    "        dataset = Data(df[:100], load_batch_size = 30, tokenizer=tokenizer, cls_model=cls_model)  # 10 > 30 > 40 yes # 4 is the best\n",
    "\n",
    "    train_dataset, val_dataset, test_dataset = utils.data.random_split(dataset,(0.8, 0.1, 0.1))\n",
    "    train_dataloader = DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle=True)\n",
    "    val_dataloader = DataLoader(dataset = val_dataset, batch_size = batch_size, shuffle=True)\n",
    "    test_dataloader = DataLoader(dataset = test_dataset, batch_size = batch_size, shuffle=True)\n",
    "    return {'data': dataset, 'train': train_dataloader, 'val': val_dataloader, 'test': test_dataloader}\n",
    "\n",
    "# THIS IS LEGACY\n",
    "# dataloader = DataLit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccfbc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, RobertaForCausalLM, AutoConfig\n",
    "# import torch\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# config = AutoConfig.from_pretrained(\"roberta-base\")\n",
    "# config.is_decoder = True\n",
    "# model = RobertaForCausalLM.from_pretrained(\"roberta-base\", config=config)\n",
    "\n",
    "# inputs = tokenizer(\"Hello, my dog is cute\", return_tensors=\"pt\")\n",
    "# # outputs = model(**inputs)\n",
    "\n",
    "# # prediction_logits = outputs.logits\n",
    "\n",
    "# inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62fc012",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "df = load_dataset('../dataset/training.json', test=True)\n",
    "\n",
    "# # # XLNet: https://huggingface.co/docs/transformers/model_doc/xlnet # size = 768\n",
    "# # # Might be able to use XLNetTokenizerFast\n",
    "# xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased') # XLNetTokenizer\n",
    "# xlnet_cls_model = XLNetModel.from_pretrained('xlnet-base-cased') # XLNetModel\n",
    "# xlnet_dataloaders = get_dataloaders(df, xlnet_tokenizer, xlnet_cls_model, BATCH_SIZE)\n",
    "\n",
    "# # ALBERT: https://huggingface.co/docs/transformers/model_doc/albert # size = 768\n",
    "albert_tokenizer = AlbertTokenizer.from_pretrained(\"albert-base-v2\")\n",
    "albert_cls_model = AlbertModel.from_pretrained(\"albert-base-v2\") # AlbertModel\n",
    "albert_dataloaders = get_dataloaders(df, albert_tokenizer, albert_cls_model, BATCH_SIZE)\n",
    "\n",
    "# # ELECTRA: 256\n",
    "electra_tokenizer = AutoTokenizer.from_pretrained(\"google/electra-small-discriminator\")\n",
    "electra_cls_model = ElectraModel.from_pretrained(\"google/electra-small-discriminator\")\n",
    "electra_dataloaders = get_dataloaders(df, electra_tokenizer, electra_cls_model, BATCH_SIZE)\n",
    "\n",
    "# # Roberta: 768\n",
    "# roberta_tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
    "# roberta_cls_model = RobertaModel.from_pretrained(\"roberta-base\")\n",
    "# roberta_dataloaders = get_dataloaders(df, roberta_tokenizer, roberta_cls_model, BATCH_SIZE)\n",
    "\n",
    "# svm_data = Data.concat([xlnet_dataloaders['data'], albert_dataloaders['data'], electra_dataloaders['data'], roberta_dataloaders['data']])\n",
    "svm_data = Data.concat([albert_dataloaders['data'], electra_dataloaders['data']])\n",
    "svm_dataloaders = get_dataloaders(dataset = svm_data)\n",
    "\n",
    "# EVERYTHING CAN HAVE BATCH SIZE 4 BUT THIS CANNOT EVEN WORK W BATCH SIZE = 1\n",
    "# DebertaV2: 1536 # Can use DebertaV3\n",
    "# debertav2_tokenizer = DebertaV2Tokenizer.from_pretrained(\"microsoft/deberta-v2-xlarge\")\n",
    "# debertav2_cls_model = DebertaV2Model.from_pretrained(\"microsoft/deberta-v2-xlarge\")\n",
    "# debertav2_dataloaders = get_dataloaders(df, debertav2_tokenizer, debertav2_cls_model, BATCH_SIZE)\n",
    "\n",
    "# dataloaders = roberta_dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8255243d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_data = Data.concat([albert_dataloaders['data'], electra_dataloaders['data']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cecbe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(svm_data.x,df['label'].tolist(),\n",
    "                                   random_state=104, \n",
    "                                   test_size=0.2, \n",
    "                                   shuffle=True)\n",
    "\n",
    "\n",
    "svc = SVC()\n",
    "svc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cea4325",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a32c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = SoftMaxLit(768, 2)\n",
    "# trainer = pl.Trainer(max_epochs=5)\n",
    "\n",
    "# # THIS IS LEGACY\n",
    "# # trainer.fit(model, dataloader)\n",
    "\n",
    "# trainer.fit(model=model, train_dataloaders=dataloaders['train'], val_dataloaders=dataloaders['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e555376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.test(model, dataloaders=dataloaders['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e6a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %reload_ext tensorboard\n",
    "# %tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26223c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.concat([ALBERT_Data, XLNet_Data, ...])\n",
    "\n",
    "# # Ensemble model using concatenation of embedding outputs\n",
    "# SVM(x: [\n",
    "#     0: concat([ALBERT_embedding, XLNet_embedding, ...]),\n",
    "#     1: ...\n",
    "#     2: ...\n",
    "#     n: ...\n",
    "# ], y: [0, 1, 1, 0, ...])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f48f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensemble - stacking:\n",
    "# LogisticReggresion([{'x': [xlnet_y_hat, albert_y_hat, roberta_y_hat, svm_y_hat, ..., detecllm_y_hat], 'y': 1}])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
